# 人工智能伦理道德
## ai如何做决策？——道德技术的构造
### 道德技术
减速带等环境说服技术、社交机器人  
### 经典案例
电车难题-功利主义、义务论  

应急处置权，决定紧急情况下如何取舍  

人工智能系统进行道德决策会引发社会心理层面挑战  
### ai如何做决策
人工智能作为道德决策的合作者辅助者更容易被人接受

ai的三种角色：  

* 人工道德能动者：代替人类直接做出选择
* 人工道德顾问：提供建议
* 苏格拉底式助手：通过苏格拉底式问答，促进个体进行道德反思，提高道判断或推理能力

个体化伦理应用指导系统

* 动态分析
* 道德一致性检查


ai道德增强的道德挑战：  

* 道德行为自动化：道德行为变得机械化和工具化人的人工智能化。
* 道德多样性的削弱：削弱了不同文化和个体间的道德多样性
* 道德责任的稀释：个体依赖于外部技术，产生不需要承担完全的道德责任的错觉

## ai犯错谁来担责——人机协同的责任归属
### ai伦理道德
一定要规则吗？
保险、公共基金。集体承担风险。  
困难：  
前提：不掺杂任何人为失误  

统一规则：道德共识  
困难：  
复杂性  
道德偏好存在跨文化属性  

谁来担责   
能承担责任的条件：  
控制条件：责任人需要控制自己的行为  
认知条件：责任人需要知道自己在做什么（人工智能不符合）  

决定使用自动驾驶汽车就承担了可能发生事故的责任  

自动驾驶的六个等级L0-L4（有条件自动驾驶/非完全自动驾驶），L5（完全自动驾驶）  

