# 人工智能伦理原则
## 人工智能伦理概述
### 带来的风险
* 内生风险
    * 深度伪造技术
    * 人工智能幻觉-编造错误的事实
* 衍生风险
    * 个人层面：个人隐私、自主性等人格尊严
    * 社会层面：对社会正义、就业、公共安全等带来风险
    * 社会层面：能源消耗、数字鸿沟
    * 军事、教育、日常认知...

### 人工智能伦理核心议题
#### 哲学讨论  
进路一：人工智能是否能成为道德主体而承担责任  
进路二：人机道德责任分配问题  

#### 技术层面
技术设计：伦理嵌入人工智能设计  
技术上的两种进路：  
自上而下-从理论或原则出发规划ai发展方向  
自下而上-通过具体实践情境的归纳得出伦理规约路径  

预防性的积极方式：  
价值敏感设计  
伦理嵌入设计  
我国2021《新一代人工智能伦理规范》 

#### 人工智能伦理的治理实践  
伦理治理框架  

* 中国：“原则-规范-审查”  
    * 2019《新一代人工智能治理原则》-和谐友好、安全可控等八项核心准则
    * 2021《...伦理规范》，细化18项伦理要求
    * 2023《科技伦理审查办法》人机融合系统、自动化决策等七类高风险研发活动的伦理审查标准
* 欧盟：伦理引导+法律约束
    * 2019《可信人工智能指南》可信人工智能概念和七项关键要求
    * 2023《人工智能法案》基于风险的分级监管体系，形成双轨制治理模式
* 国际社会加紧推进合作，构建新秩序
    * 2025全球人工智能行动峰会

## 原则主义的治理框架
### 阿西莫夫机器人三定律
伦理框架-人类安全至上  

揭示了两个关键问题：  
原则必须明确价值排序  
原则刚性往往无法应对现实复杂性  

### 科技伦理治理中的原则主义
伦理原则：指在面对伦理决策时，用来知道行为的基本规范和价值标准  

原则主义：一种以两个或更多没有固定等级排序的原则作为基本框架的伦理分析进路，是生命伦理学诸多分析进路中最具影响力的一种。  
比彻姆和丘卓斯：《生命医学伦理原则》提出四个基本原则-自主、有利、不伤害、公正  

原则主义的科技伦理实践  
国家层面：为国家科技发展提供理论指引  
行业层面：制定了复合自身特点的伦理原则，构建行业发展的伦理框架  
技术层面：为新兴技术的政策法规提供了价值基础  

* 国际社会2021《人工智能伦理问题建议书》
    * 4项价值观、10项伦理原则、11项政策建议
* 中国2019《新一代人工智能治理原则》
* 欧盟2019《可信人工智能指南》
* 美国2023《人工智能委员会报告》
* 微软、谷歌

### 伦理原则
伦理洗涤：伦理粉饰的行为，仅承诺不实践  
高阶伦理原则的重要作用之一