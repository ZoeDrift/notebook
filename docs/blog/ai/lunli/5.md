# 人工智能公平性
## 揭开AI公平面具的技术真相
### 人工智能歧视的案例
偏见  
歧视  

Midjourney生成古文明图像偏差  

人脸识别软件对女性和深色人种识别偏差  

woebot对ptsd患者歧视性回应  

### 为什么人工智能存在偏见与歧视

* 数据偏见导致AI偏见
    * 原始数据可能自带社会偏见
    * 数据标注过程会植入主观判断
* 模型偏见导致AI偏见
    * 优化目标偏差。核心矛盾：数学最优解不等于社会最优解
    * 特征选择偏见。指因特征工程阶段选择或构造的输入变量与敏感属性，导致模型决策产生系统性歧视的现象。
* 人类干预导致AI偏见


## 人工智能正义手册：破解AI公平性的达芬奇密码
### 人工智能公平性基本概念
人工智能公平

* 技术公平
    * 往往被解构为统计指标间的平衡游戏
    * 人工智能的技术公平：对同一类任务，人工智能对不同群体的预测结果应保持统计无差异
    * 群体角度
        * 隐式公平：AI预测结果与敏感属性无关
        * 群组公平：在不同群体基本均等
        * 预测平等：与真是对比，不同群体的假阳率/假阴率一致
    * 个体角度
        * 个体公平：个体水平上看公平
        * 因果公平：从反事实假设的角度看公平
* 伦理公平
    * 不仅要求算法输出结果的统计均衡，还突破了数学模型的参数优化框架，指向技术系统对社会权利结构、历史不公与人类主体性的深刻回应。

人工智能的公平性并非平等主义  
不等于绝对平等，合理差异化对待是公平的重要维度。  

### 提高ai公平性的方法
#### 技术层面

* 预处理-消除训练集偏见  
    * 技术一：平衡数据集。
    * 技术二：审查调整数据集。对训练数据集进行检查，发现其中可能存在的偏见，REVISE
    * 技术三：合成成对数据进行数据增强。在构建数据集时，令两种不同类的属性的样本成对增大，始终保持其平衡性。
* 模型训练-公平性约束  
    * 技术四：引入公平性约束。将公平性约束作为优化的一部分，在最小化损失函数的同时也能最大限度地减少偏见。
    * 技术五：对抗训练方法。构建一个额外的对抗网络，该网络尝试预测模型的敏感属性，如性别、种族等。
* 后处理-对输出值进行处理  
    * 通过调整输出结果或优化决策逻辑，消除预测结果中可能存在的偏见。
    * 建立公平性指标与预测结果之间的映射关系。
    * 不改变模型本身

#### 法律层面
* 人工智能公平性相关立法是保障人工智能公平性的基石

#### 企业层面
制定责任框架，建立三级审核机制：

* 数据审核
* 算法评测
* 第三方审计